{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To review arrays and slicing, let's do an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion using random walks\n",
    "The following example has been adapted from [scipylectures.org](https://scipy-lectures.org/intro/numpy/operations.html#basic-reductions).   \n",
    "\n",
    "The random walk process is a commonly used example in physics and mathematics. \n",
    "We will model the diffussion of a particle in a one dimensional grid using a random walk. The particle starts at the origin at $t=0$ and at each time step jumps right or left with equal probability. A step towards left is denoted by a displacement of `-1` units and a step towards right is `+1` units. See below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/img/random_walk_1.png\" height=100 width=450>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We want to find the typical distance (in units of grid points) from the origin of a random walker after `t` left or right jumps.**\n",
    "\n",
    "To achieve this, we will generate a random trajectory for a walker. We will also generate a lot of such walks (let's call them *stories*) and check their statistical properties to find a pattern.\n",
    "\n",
    "The simulation will be done using NumPy array computing tricks: we are going to create a 2D array with the *stories* along one axis and *time* along another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/img/random_walk_schema_1.png\" height=300px width=300px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stories = 10000 # number of stories i.e the maximum number of independent walks\n",
    "t_max = 200      # time during which we follow the walker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create the array of steps taken by the walkers shown in the above schema using the function `np.random.choice()`. The first argument will be a list of values from which the numbers will be chosen i.e. `[-1,1]`. The second argument will be a tuple denoting the shape of the array to be created, i.e. using `n_stories` and `t_max`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call `np.random.choice`, it will randomly select an element from `[-1,1]` to populate each element of our new array, with size `n_stories` by `t_max`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = np.random.choice()      # COMPLETE THIS LINE OF CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the *displacement* from the origin for each of the walker as a function of time by calculating the cumulative sum of the steps **along the time axis** using `np.cumsum()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./data/img/random_walk_schema_2.png\" height=300px width=300px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacements = np.cumsum()     # COMPLETE THIS LINE OF CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now find the root mean squared displacement as a function of time by calculating the statistic along the axis of the *stories*. You can use the `np.sqrt()`, `np.mean` and `**` (or `np.power`) functions and operations. Use\n",
    "$$RMS = \\sqrt{\\frac{1}{n} \\sum_{i} x_i^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE THESE THREE LINES OF CODE\n",
    "sq_displacement =                      # squared displacement\n",
    "mean_sq_disp = np.mean( )        # mean squared displacement along the story axis\n",
    "rms_disp =  np.sqrt( )                       # root mean squared displacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot our results, we first *generate* an array containing the time steps to plot the RMS displacement versus time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the time axis\n",
    "t = np.arange( )             # COMPLETE THIS LINE OF CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also plot a $\\sqrt{t}$ in the same plot to compare to our simulated random walk process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(12,8))\n",
    "\n",
    "ax.scatter(t, rms_disp, label=\"Simulation\", marker=\"x\", c=\"C0\")\n",
    "ax.plot(t, np.sqrt(t), label=r\"$t$\", c=\"C1\", lw=2)\n",
    "ax.legend()\n",
    "ax.set_xlabel(r\"$t$\", fontsize=20) \n",
    "ax.set_ylabel(r\"$\\sqrt{\\langle (\\delta x)^2 \\rangle}$\", fontsize=20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find a well-known result in physics: the RMS distance grows as the square root of the time!   \n",
    "\n",
    "To get a feel of how efficiently we did all the above calculations on such a huge number of elements, let us time the code used to do all the calculations. Paste the all code to do the calculations (except plotting) in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# PASTE THE CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison we will do a very simple calculation on the same number of elements using native Python. I hope this helps you to appreciate vectorized calculations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "vals = [i for i in range(n_stories*t_max)]\n",
    "new_vals = [i+1 for i in vals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fancy Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean arrays and logical operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like `int` and `float` the elements of a NumPy array can also be boolean values i.e. `True` or `False`. These arrays may be created as a result of element wise comparison between two arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([1, 2, 3, 4])\n",
    "b1 = np.array([4, 2, 2, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you expect the output of these operations to be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** if we want to check whether two arrays are identical to each other, we can use the function `np.array_equal()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = a1 == b1\n",
    "expected = \n",
    "\n",
    "print(np.array_equal(expected,actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "actual = a1 >= b1\n",
    "expected = \n",
    "\n",
    "print(np.array_equal(expected,actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Element wise logical operations can be done using built in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = np.array([True, True, False, False])\n",
    "b2 = np.array([True, True, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = np.logical_and(a2, b2)\n",
    "expected = \n",
    "\n",
    "print(np.array_equal(actual, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 & b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** In addition to the predefined functions shown above the binary operators `&`, `|` and `~` can also be used to determine the element wise logical AND, OR and NOT.   \n",
    "When performing `sum()` on boolean arrays, the `True` values are treated as 1 and `False` as zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to convert an integer array to a Boolean, with 0s treated as `False` and any non-zero element as `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = np.array([1, 2, 3, 4, 0, 0, -5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3.astype(bool).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a boolean array that returns true if the array element of `a1` is the same as `b1` but different than `c1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([1, 2, 3, 4])\n",
    "b1 = np.array([4, 2, 2, 4])\n",
    "c1 = np.array([3, 3, 3, 3])\n",
    "\n",
    "# Write code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count how many elements a1 has in common with b1 or c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing with boolean arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If instead of using integers we index arrays with other boolean arrays of same (or compatible) shape, the returned array will be composed of elements of the original array for which the corresponding boolean index was True. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1[[True, False, False, True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may have an array of data where negative values indicate some kind of error. We can use a boolean *mask* to select array elements which satisfy our criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.2, 2.8, 3.5, -999, 2.7, 4.8, -999])\n",
    "\n",
    "mask = (x > 0)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally it is done in a single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[x>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also set specific values for array elements which satisfy our criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[x<0] = np.nan\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** `np.nan` is a special data object (of type `float`) which is used to denote invalid or missing values. NumPy is built to gracefully handle invalid or missing data points as long as they are marked with `NaN` (Not a Number). This is the recommended way of doing this instead of the more traditional way of denoting missing data with absurd numbers. For convenience, NumPy has a host of such special constants defined which are listed [here](https://numpy.org/doc/stable/reference/constants.html?highlight=constants)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return an array with the elements that are in both `a1` and `b1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace all values of the array below that are either negative or less than one with `nan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1.5, -3.4, -0.1, 2.],[-0.9, 0.4, 1.1, 0.8]])\n",
    "\n",
    "# Write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Boolean Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.logical_and` and `np.logical_or` functions only take two arrays as arguments. Sometimes, you may want to compare more than two boolean arrays. In the examples above we acomplished this task like this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = np.array([True, True, False, False])\n",
    "b2 = np.array([True, True, False, False])\n",
    "c2 = np.array([False, True, False, True])\n",
    "\n",
    "a2 & b2 & c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the function \"reduce\". This is a function of the `np.logical_and` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logical_and.reduce?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using the reduce function to compare arrays a2, b2, and c2 simultaneously. Use the docstring to determine the correct syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logical_and.reduce( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is especially useful if we have many arrays to reduce...or even a multidimensional array to reduce! For example, let's say we have a 2-dimensional array representing the grades of each student for several assignments where each row represents a student and each column represents an assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradebook = np.array([[0.73, 0.65, 0.92, 0.82],\n",
    "                      [0.77, 0.82, 0.83, 0.93],\n",
    "                      [0.60, 0.54, 0.95, 0.89]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using the np.logical_and.reduce() function to find out if all students got above a 75% on each assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logical_and.reduce( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate which students received above a 75% on every assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logical_and.reduce( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Masking lines in a spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `.npy` file (`data/sdss_spectra.npy`) has been provided containing the spectrum of a galaxy. \n",
    "- The `0th` axis corresponds to the wavelength sampling \n",
    "- The `1th` axes has 3 elements: \n",
    "    - The `0th` element is the wavelength grid \n",
    "    - The `1th` element is the measured (and normalized) flux and \n",
    "    - The `2th` element gives the flux errors \n",
    "    \n",
    "First, let's read in the data and unpack them into separate arrays.\n",
    "\n",
    "When plotting data from a file I haven't used before, I personally always like to 'look' at the data so I can understand its shape better. I have attached print statements to help. I look at the shape of the data and then an element of the data.  In addition, whenever I perform an operation which may change the shape of the data, I also print the shape again to make sure it is changed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./data/sdss_spectra.npy\")\n",
    "#COMPLETE THESE THREE LINES OF CODE\n",
    "\n",
    "#\n",
    "data = np.load( ) #read in the data\n",
    "print( )\n",
    "print( ) # This prints the very first element of our wavelength sampling\n",
    "#\n",
    "\n",
    "wavelength = data[:,0] #allocate the proper 1D slices\n",
    "flux = data[:,1]\n",
    "flux_err = data[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hard part is done, let's plot the spectrum!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(wavelength, flux, label=\"Flux\")\n",
    "plt.plot(wavelength, flux_err, label=\"Error\")\n",
    "plt.ylim(-1,2)\n",
    "plt.xlabel(\"Wavelength [$\\AA$]\", fontsize=20)\n",
    "plt.ylabel(\"Normalized Flux [Arbitrary Units]\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This spectrum looks good but there are large errors here. We should reject all flux values for which the error is greater than 0.2. We will first create a boolean mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "good_data_mask =  #COMPLETE THIS LINE OF CODE\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use this mask to index our arrays.\n",
    "\n",
    "Remember: We can do this one of two ways, we can use our recently created `good_data_mask` or we can use a logic statment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPLETE THESE TWO LINES OF CODE\n",
    "#\n",
    "good_wavelength = \n",
    "good_flux = \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our masked array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.plot(good_wavelength, good_flux, label=\"Flux\")\n",
    "ax.plot(wavelength, flux_err, label=\"Error\")\n",
    "ax.set_ylim(-0.75, 0.75)\n",
    "ax.set_xlabel(\"Wavelength [$\\AA$]\", fontsize=20)\n",
    "ax.set_ylabel(\"Normalized Flux [Arbitrary Units]\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see emission and absorption lines in the above spectrum. Let's try to get rid of them by keeping flux values which are less than $2\\sigma$ away from the mean. \n",
    "\n",
    "i.e. $F - \\bar{F} < \\pm 2\\sigma$\n",
    "\n",
    "For this you need to use the numpy functions `np.mean()`, `np.std()` and the `&` boolean operator. (Alternatively the `np.abs()` function can also be used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPLETE THIS LINE OF CODE\n",
    "#\n",
    "cont_mask = \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot and see what we have selected using this mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_wavelength = good_wavelength[cont_mask]\n",
    "cont_flux = good_flux[cont_mask]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "ax.plot(good_wavelength, good_flux, label=\"Flux\", ls=\"--\", alpha=0.8)\n",
    "ax.plot(cont_wavelength, cont_flux, label=\"Clipped Flux\")\n",
    "\n",
    "ax.set_ylim(-0.75, 0.75)\n",
    "ax.set_xlabel(\"Wavelength [$\\AA$]\", fontsize=20)\n",
    "ax.set_ylabel(\"Normalized Flux [Arbitrary Units]\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that's a good looking spectrum!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Measuring the strength of a line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have provided a data file (`sn_data.npy`) which contains multiple spectra of a supernova as it evolves over time.  These \"data\" are calculated theoretically from a radiative-transfer code.  I would like to analyze the spectra to see how the emission from <b>carbon monoxide</b> changes over time.  \n",
    "\n",
    "\n",
    "\n",
    "This is a large data file with a lot of dimensions, so let's examine it carefully and make sure we understand its structure before doing calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and examine the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's load in the data the same as before, using `np.load`, and look at its shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPLETE THESE LINES OF CODE\n",
    "\n",
    "#fill in these (same as previous example)\n",
    "\n",
    "#\n",
    "sn_data_path =  #set the path to the data file\n",
    "sn_data =  #read in the data\n",
    "print( ) #print the data shape\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you look at the <b>shape</b> of this data, you should notice that one of the dimensions has a size of 1.  You might call this a <i>dummy</i> dimension, because it isn't adding to the data:  the array including this dimension contains exactly the same data as without it.  To make dealing with this data simpler, we can reduce the number of dimensions without losing any information.  This data array also contains lots of redundant information, which we will try to deal with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the shape of the data array using `np.reshape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.reshape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove the dummy dimension using reshape\n",
    "\n",
    "#\n",
    "reshaped_sn_data = np.reshape( )\n",
    "print( ) #print the new shape\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the remaining data, the `zeroth` axis (size 15) is the time axis.  The `first` axis (size 3) is the type of information:\n",
    "- index `0` is the spectrum\n",
    "- index `1` is the wavelength array\n",
    "- index `2` is the time after explosion (in days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `second` dimension is the number of data points in the spectrum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the day is a scalar, but in the data it is given as an array, like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshaped_sn_data[0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays are <b>rectangular</b>, which means that all the elements must have the same size.  A Numpy array cannot have different size elements along the same axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull out the time information into a separate array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_list = reshaped_sn_data[:,2,0]\n",
    "print(day_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the first and last spectra to see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.plot(reshaped_sn_data[0][1], reshaped_sn_data[0,0], label=f\"Day {reshaped_sn_data[0,2,0]}\")\n",
    "ax.plot(reshaped_sn_data[-1][1], reshaped_sn_data[-1,0], label=f\"Day {reshaped_sn_data[-1,2,0]}\")\n",
    "ax.set_xlim(0, 60000)\n",
    "ax.set_xlabel(\"Wavelength [$\\AA$]\", fontsize=20)\n",
    "ax.set_ylabel(\"Flux [erg $s^{-1} \\; cm^{-2} \\; \\AA^{-1}$]\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that the supernova gets dimmer over time as it cools.  Now let's look at the emission from <b>carbon monoxide</b>, which arises in the infrared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.plot(reshaped_sn_data[0][1]/1e4, reshaped_sn_data[0,0], label=f\"Day {reshaped_sn_data[0,2,0]}\")\n",
    "ax.plot(reshaped_sn_data[-1][1]/1e4, reshaped_sn_data[-1,0], label=f\"Day {reshaped_sn_data[-1,2,0]}\")\n",
    "rect1 = patches.Rectangle([4.25, 0], 1.5, 2e-8, alpha=0.2, zorder=-np.inf, edgecolor=None, facecolor='tab:green', label='CO emission region')\n",
    "ax.add_patch(rect1)\n",
    "ax.set_xlim(3, 7)\n",
    "ax.set_ylim(-1e-9, 2e-8)\n",
    "ax.set_xlabel(\"Wavelength [$\\mu m$]\", fontsize=20)\n",
    "ax.set_ylabel(r\"Flux [erg $s^{-1} \\; cm^{-2} \\; \\AA^{-1}$]\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the situation is a little more complicated: the emission from <b>carbon monoxide</b> increases over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's make a plot of the Carbon Monoxide emission as a function of time for this supernova model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although explicitly listed for each time step, the wavelength arrays are actually identical.  We can check that using boolean operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(reshaped_sn_data[0,1,:] == reshaped_sn_data[1,1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.all` function checks whether <b>all</b> the elements of an array are true.  Similarly useful is the `np.any` function, which returns True if at least one element of the array is True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CO band region covers 4.2 to 5.7 $\\mu$m. To convert from $\\mu$m to $\\unicode{0x0000212B}$, use the relation $1 \\mu m = 10000 \\unicode{0x0000212B}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a Boolean mask which covers the CO band region\n",
    "\n",
    "sn_wav = reshaped_sn_data[0,1,:]\n",
    "\n",
    "#\n",
    "co_region = \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main <b>carbon monoxide</b> emission band covers a broad region ($\\sim$4.3 to 5.5 $\\mu$m), so we cannot clip it out like we can with narrow lines. Moreover, we can't directly measure the amount of emission coming from carbon monoxide, because we don't know where the <b>continuum</b> lies in this region.  What we can do is look at what fraction of the <i>total</i> emission comes from the CO band region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `np.trapz` to calculate the area under a curve numerically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.trapz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculate the total luminosity of all the spectra\n",
    "\n",
    "#\n",
    "total_luminosities = np.trapz( )\n",
    "#\n",
    "\n",
    "print(total_luminosities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "\n",
    "ax.plot(day_list, total_luminosities, marker='o', markersize=10)\n",
    "\n",
    "ax.set_xlabel('Days After Explosion')\n",
    "ax.set_ylabel(r'Total Flux (erg $s^{-1} \\; cm^{-2}$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now calculate the integrated luminosity just in the co region, using our Boolean mask\n",
    "#!Don't forget to mask the wavelength array as well!\n",
    "\n",
    "# \n",
    "co_luminosities = np.trapz( )\n",
    "#\n",
    "\n",
    "print(co_luminosities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "\n",
    "ax.plot(day_list, co_luminosities/total_luminosities, marker='o', markersize=10)\n",
    "\n",
    "ax.set_xlabel('Days After Explosion')\n",
    "ax.set_ylabel('CO Band Fraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relative amount of emission from carbon monoxide increases significantly over time! \n",
    "\n",
    "This is because carbon monoxide takes time to form in the supernova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
